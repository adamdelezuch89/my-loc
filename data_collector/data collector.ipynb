{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collector\n",
    "Tool for downloading rivers data from OpenStreeMap and converting to csv format.\n",
    "\n",
    "## Usage\n",
    "Please set name of river - if you want to collect specific river or coordinates of area - to download all rivers from that area.\n",
    "\n",
    "And run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_name = \"WisÅ‚a\"  # Keep empty if you want to collect rivers from area\n",
    "# Define coordinates for the bounding box (southwest and northeast corners)\n",
    "rivers_area = (\n",
    "    50.0,\n",
    "    14.0,\n",
    "    54.0,\n",
    "    24.0,\n",
    ")  # For example coords for polish rivers: (50.0, 14.0, 54.0, 24.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "# Define the Overpass API endpoint\n",
    "OVERPASS_URL = \"http://overpass-api.de/api/interpreter\"\n",
    "\n",
    "\n",
    "if river_name:\n",
    "    collection_name = unidecode(river_name.lower())\n",
    "    # Define the Overpass query to get the specified river\n",
    "    overpass_query = f\"\"\"\n",
    "[out:json];\n",
    "way[\"waterway\"=\"river\"][\"name\"=\"{river_name}\"];\n",
    "out body;\n",
    ">;\n",
    "out skel qt;\n",
    "\"\"\"\n",
    "\n",
    "elif rivers_area:\n",
    "    collection_name = \"rivers\"\n",
    "    # Define the Overpass query to get all rivers using the coordinates\n",
    "    overpass_query = f\"\"\"\n",
    "[out:json];\n",
    "way[\"waterway\"=\"river\"]{rivers_area}; \n",
    "out body;\n",
    ">;\n",
    "out skel qt;\n",
    "\"\"\"\n",
    "else:\n",
    "    raise ValueError(\"Either river_name or rivers_area must be provided\")\n",
    "\n",
    "collection_path = os.path.join(DATA_PATH, collection_name)\n",
    "os.makedirs(collection_path, exist_ok=True)\n",
    "\n",
    "# Define the output file\n",
    "raw_geojson_file = os.path.join(collection_path, \"raw.geojson\")\n",
    "\n",
    "\n",
    "# Send the request to Overpass API\n",
    "response = requests.post(OVERPASS_URL, data={\"data\": overpass_query})\n",
    "\n",
    "# Check if the response is successful\n",
    "if response.status_code != 200:\n",
    "    print(\"Error: Received response code\", response.status_code)\n",
    "    exit(1)\n",
    "\n",
    "# Parse the JSON response\n",
    "data = response.json()\n",
    "\n",
    "# Check if the response contains data\n",
    "if not data or \"elements\" not in data or not data[\"elements\"]:\n",
    "    print(\"Error: No elements found in the response.\")\n",
    "    exit(1)\n",
    "\n",
    "# Save the response to the output file\n",
    "with open(raw_geojson_file, \"w\") as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "# Check if the output file is not empty\n",
    "if os.path.getsize(raw_geojson_file) > 0:\n",
    "    print(\"Download complete:\", raw_geojson_file)\n",
    "else:\n",
    "    print(\"Error: Output file is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded json has nested structure, but interesting one is \"elements\" property. It stores object with two types (property \"type\") - \"ways\" for rivers and \"node\" for node. \n",
    "One river is separated for many smaller parts called ways. every way has start and end coordinates. They are nodes. Lets create separated files for ways and nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the JSON file\n",
    "with open(raw_geojson_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "ways_file = os.path.join(collection_path, \"raw_ways.json\")\n",
    "nodes_file = os.path.join(collection_path, \"raw_nodes.json\")\n",
    "\n",
    "# Step 2: Filter elements into nodes and ways\n",
    "nodes = []\n",
    "ways = []\n",
    "\n",
    "for element in data.get(\"elements\", []):\n",
    "    if element.get(\"type\") == \"node\":\n",
    "        nodes.append(element)\n",
    "    elif element.get(\"type\") == \"way\":\n",
    "        ways.append(element)\n",
    "\n",
    "# Step 3: Write nodes to a file\n",
    "with open(nodes_file, \"w\") as f:\n",
    "    json.dump(nodes, f, indent=4)\n",
    "\n",
    "# Write ways to a file\n",
    "with open(ways_file, \"w\") as f:\n",
    "    json.dump(ways, f, indent=4)\n",
    "\n",
    "print(\"Files created: nodes.json and ways.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets simplify structure and split data to final datasets:\n",
    "\n",
    "**ways**\n",
    "* id\n",
    "* name\n",
    "* boat (https://wiki.openstreetmap.org/wiki/Key:boat)\n",
    "* waterway (https://wiki.openstreetmap.org/wiki/Key:waterway)\n",
    "* motorboat (https://wiki.openstreetmap.org/wiki/Key:motorboat)\n",
    "* fixme (https://wiki.openstreetmap.org/wiki/Key:fixme)\n",
    "\n",
    "**nodes**\n",
    "* way_id\n",
    "* lat\n",
    "* lon\n",
    "\n",
    "**ways_names**\n",
    "* way_id\n",
    "* language_code\n",
    "* name\n",
    "\n",
    "**ways_nodes**\n",
    "* way_id\n",
    "* node_id\n",
    "* sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read the nested JSON file\n",
    "with open(ways_file, \"r\") as f:\n",
    "    raw_ways_data = json.load(f)\n",
    "\n",
    "# Prepare a list to hold processed data\n",
    "ways_data = []\n",
    "ways_nodes_data = []\n",
    "ways_names_data = []\n",
    "\n",
    "# Extract relevant information from each object\n",
    "for way in raw_ways_data:\n",
    "    way_id = way.get(\"id\")\n",
    "    tags = way.get(\"tags\", {})\n",
    "\n",
    "    # Create a dictionary with all tags and their values\n",
    "    way_data = {\"id\": way_id}\n",
    "    way_data.update(tags)  # Add all tags to the dictionary\n",
    "\n",
    "    ways_data.append(way_data)\n",
    "    # Extract nodes information\n",
    "    nodes = way.get(\"nodes\", [])\n",
    "    for sequence, node_id in enumerate(nodes):\n",
    "        ways_nodes_data.append(\n",
    "            {\"way_id\": way_id, \"node_id\": node_id, \"sequence\": sequence}\n",
    "        )\n",
    "\n",
    "    # Extract names with language codes\n",
    "    for key, value in tags.items():\n",
    "        if key.startswith(\"name:\"):\n",
    "            language_code = key.split(\":\")[1]  # Get the language code from the key\n",
    "            ways_names_data.append(\n",
    "                {\"way_id\": way_id, \"language_code\": language_code, \"name\": value}\n",
    "            )\n",
    "\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "ways_df_full = pd.DataFrame(ways_data)\n",
    "ways_nodes_df = pd.DataFrame(ways_nodes_data)\n",
    "ways_names_df = pd.DataFrame(ways_names_data)\n",
    "\n",
    "\n",
    "# Specify the columns to keep in the CSV\n",
    "ways_columns_reduced = [\"id\", \"name\", \"boat\", \"waterway\", \"motorboat\", \"fixme\"]\n",
    "ways_columns_reduced = [col for col in ways_columns_reduced if col in ways_df_full.columns] # Filter out non existing columns\n",
    "\n",
    "ways_df_reduced = ways_df_full[ways_columns_reduced]\n",
    "# Save only specified columns to a CSV file\n",
    "ways_csv = os.path.join(collection_path, \"ways.csv\")\n",
    "ways_df_reduced.to_csv(ways_csv, index=False)\n",
    "\n",
    "# Save nodes data to a CSV file\n",
    "ways_nodes_csv = os.path.join(collection_path, \"ways_nodes.csv\")\n",
    "ways_nodes_df.to_csv(ways_nodes_csv, index=False)\n",
    "\n",
    "# Save names data to a CSV file\n",
    "ways_names_csv = os.path.join(collection_path, \"ways_names.csv\")\n",
    "ways_names_df.to_csv(ways_names_csv, index=False)\n",
    "\n",
    "print(\"CSV file 'ways.csv' created successfully!\")\n",
    "print(\"CSV file 'ways_nodes.csv' created successfully!\")\n",
    "print(\"CSV file 'ways_names.csv' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open(nodes_file, \"r\") as f:\n",
    "    nodes_data = json.load(f)\n",
    "\n",
    "# Create a DataFrame with only the specified columns\n",
    "nodes_df = pd.DataFrame(nodes_data)[[\"id\", \"lat\", \"lon\"]]\n",
    "\n",
    "nodes_csv = os.path.join(collection_path, \"nodes.csv\")\n",
    "# Save the DataFrame to a CSV file\n",
    "nodes_df.to_csv(nodes_csv, index=False)\n",
    "\n",
    "print(\"CSV file 'nodes.csv' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ways: {ways_df_reduced.shape[0]}\")\n",
    "print(f\"ways_nodes: {ways_nodes_df.shape[0]}\")\n",
    "print(f\"ways_names: {ways_names_df.shape[0]}\")\n",
    "print(f\"nodes: {nodes_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
